{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NwvpmH3YVbX",
    "outputId": "7390d51e-956f-4063-e940-297bdf9cb331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\hrida\\appdata\\roaming\\python\\python39\\site-packages (0.9.0.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.1)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\hrida\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: numpy in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (1.22.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.5.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hrida\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/absolute/path/to/face_landmarker.task'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\hrida\\appdata\\roaming\\python\\python39\\site-packages (0.9.0.1)\n",
      "Collecting mediapipe\n",
      "  Downloading mediapipe-0.10.8-cp39-cp39-win_amd64.whl (50.5 MB)\n",
      "     ---------------------------------------- 50.5/50.5 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting sounddevice>=0.4.4\n",
      "  Downloading sounddevice-0.4.6-py3-none-win_amd64.whl (199 kB)\n",
      "     -------------------------------------- 199.7/199.7 KB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (2.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\hrida\\appdata\\roaming\\python\\python39\\site-packages (from mediapipe) (4.6.0.66)\n",
      "Requirement already satisfied: absl-py in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (1.22.4)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.14.6)\n",
      "Requirement already satisfied: six in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hrida\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.20)\n",
      "Installing collected packages: sounddevice, mediapipe\n",
      "  Attempting uninstall: mediapipe\n",
      "    Found existing installation: mediapipe 0.9.0.1\n",
      "    Uninstalling mediapipe-0.9.0.1:\n",
      "      Successfully uninstalled mediapipe-0.9.0.1Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\hrida\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\~ediapipe\\\\python\\\\opencv_world3410.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\hrida\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\hrida\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade mediapipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nE-9S_jbYX6w"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7Bj4kFuBMqgq"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "J94szJe_jlf0"
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cNFluvm3mgaE"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lSS7TeXNvCD_"
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NwaSH5yUtsXp"
   },
   "outputs": [],
   "source": [
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_Avik_TaYZkH"
   },
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CaALNtDsYbAG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[174, 192, 193],\n",
       "        [174, 192, 193],\n",
       "        [174, 192, 193],\n",
       "        ...,\n",
       "        [121, 118, 120],\n",
       "        [121, 118, 120],\n",
       "        [121, 118, 120]],\n",
       "\n",
       "       [[169, 186, 189],\n",
       "        [169, 187, 188],\n",
       "        [169, 186, 189],\n",
       "        ...,\n",
       "        [123, 120, 122],\n",
       "        [123, 120, 122],\n",
       "        [123, 120, 122]],\n",
       "\n",
       "       [[163, 179, 185],\n",
       "        [163, 180, 183],\n",
       "        [163, 179, 185],\n",
       "        ...,\n",
       "        [126, 122, 127],\n",
       "        [126, 122, 127],\n",
       "        [126, 122, 127]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[135, 137, 138],\n",
       "        [145, 149, 150],\n",
       "        [167, 169, 170],\n",
       "        ...,\n",
       "        [ 42,  38,  37],\n",
       "        [ 43,  39,  38],\n",
       "        [ 44,  40,  39]],\n",
       "\n",
       "       [[197, 201, 202],\n",
       "        [205, 210, 211],\n",
       "        [221, 225, 226],\n",
       "        ...,\n",
       "        [ 44,  40,  39],\n",
       "        [ 46,  42,  41],\n",
       "        [ 47,  43,  42]],\n",
       "\n",
       "       [[227, 232, 233],\n",
       "        [231, 236, 237],\n",
       "        [236, 241, 242],\n",
       "        ...,\n",
       "        [ 61,  57,  56],\n",
       "        [ 63,  59,  58],\n",
       "        [ 65,  61,  60]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "image = cv2.imread(\"img.jpg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  face_landmarks_list = detection_result.face_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "  for idx in range(len(face_landmarks_list)):\n",
    "        face_landmarks = face_landmarks_list[idx]\n",
    "\n",
    "        # Draw the face landmarks.\n",
    "        face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        face_landmarks_proto.landmark.extend([\n",
    "          landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks\n",
    "        ])\n",
    "\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_tesselation_style())\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp.solutions.drawing_styles\n",
    "            .get_default_face_mesh_contours_style())\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            image=annotated_image,\n",
    "            landmark_list=face_landmarks_proto,\n",
    "            connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n",
    "              landmark_drawing_spec=None,\n",
    "              connection_drawing_spec=mp.solutions.drawing_styles\n",
    "              .get_default_face_mesh_iris_connections_style())\n",
    "\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: face_landmarker_v2_with_blendshapes.task\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\"\n",
    "filename = \"face_landmarker_v2_with_blendshapes.task\"\n",
    "\n",
    "response = requests.get(url, stream=True)\n",
    "with open(filename, 'wb') as file:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:\n",
    "            file.write(chunk)\n",
    "\n",
    "print(f\"Downloaded: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.tasks.python.vision' has no attribute 'FaceLandmarkerOptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17736/3023552759.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# STEP 2: Create an FaceLandmarker object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mbase_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBaseOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_asset_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'face_landmarker_v2_with_blendshapes.task'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m options = vision.FaceLandmarkerOptions(base_options=base_options,\n\u001b[0m\u001b[0;32m      8\u001b[0m                                        \u001b[0moutput_face_blendshapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                        \u001b[0moutput_facial_transformation_matrixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'mediapipe.tasks.python.vision' has no attribute 'FaceLandmarkerOptions'"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "# STEP 2: Create an FaceLandmarker object.\n",
    "base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "# STEP 3: Load the input image.\n",
    "image = mp.Image.create_from_file(\"img.jpg\")\n",
    "\n",
    "# STEP 4: Detect face landmarks from the input image.\n",
    "detection_result = detector.detect(image)\n",
    "\n",
    "# STEP 5: Process the detection result. In this case, visualize it.\n",
    "annotated_image = draw_landmarks_on_image(image.numpy_view(), detection_result)\n",
    "cv2_imshow(cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kiLusk-kp7n"
   },
   "outputs": [],
   "source": [
    "for face in results.multi_face_landmarks:\n",
    "    for landmark in face.landmark:\n",
    "        x = landmark.x\n",
    "        y = landmark.y\n",
    "\n",
    "        shape = image.shape\n",
    "        relative_x = int(x * shape[1])\n",
    "        relative_y = int(y * shape[0])\n",
    "\n",
    "        cv2.circle(image, (relative_x, relative_y), radius=1, color=(225, 0, 100), thickness=1)\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tbefnPjluBz"
   },
   "outputs": [],
   "source": [
    "def coordinates (landmark1, landmark2, image):\n",
    "  data=np.array(image)\n",
    "  shape=data.shape\n",
    "  x1=int((results.multi_face_landmarks[0].landmark[landmark1].x)*shape[1])\n",
    "  y1=int((results.multi_face_landmarks[0].landmark[landmark1].y)*shape[0])\n",
    "  x2=int((results.multi_face_landmarks[0].landmark[landmark2].x)*shape[1])\n",
    "  y2=int((results.multi_face_landmarks[0].landmark[landmark2].y)*shape[0])\n",
    "  xmin=min(x1,x2)\n",
    "  xmax=max(x1,x2)\n",
    "  ymin=min(y1,y2)\n",
    "  ymax=max(y1,y2)\n",
    "  return (xmin,ymin,xmax, ymax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HPfpoYe3nXQU"
   },
   "outputs": [],
   "source": [
    "image=Image.open(\"1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lAebCi1OMxD"
   },
   "outputs": [],
   "source": [
    "data=np.array(image)\n",
    "shape=data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XUHvxnNNbgN"
   },
   "outputs": [],
   "source": [
    "forehead_coordinates=coordinates(333, 104, image)\n",
    "nose_coordinates=coordinates (2,6,image)\n",
    "#cheek_coordinates=coordinates (11,20, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C1JagS4EOaF_"
   },
   "outputs": [],
   "source": [
    "forehead_crop=image.crop(forehead_coordinates)\n",
    "nose_crop=image.crop(nose_coordinates)\n",
    "#cheek_crop=image.crop(cheek_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "L13b3roAwaS3",
    "outputId": "ceea4fca-a17b-46f6-99d1-b4e32fce6bb0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADoAAAAICAIAAAAna3vZAAABtUlEQVR4nH2UQXLbMAxF/wfIOJteuWfpiXqTdLzRpCUF/C4o0bRjBwsM5osCHwCS/P3rp7vbabVWkiTNbHqS6avu9KG7lQKYCJJGNzN3hzGQeGYRMQJJq2f+vel5iCYAyExFDqUMiJkuMweTpFW/MyMAkgnY/RcRIgjgBS6pgQg8+GM9JUEADBqJiBQTgElH8waZpDztTIp1AYziISZx/HUWpRfVfSHmcy9QXxafyuh0ueuNNKczgskq3lIPViOhhRVYaV+iGyWNJk8PAAHxCe6DlbW16/RHp2+6l8kqo7uTBN3dBTs/WRJSzjLWCs+0eQt1jFOSS5lZa3Wz/q8BoHv0HhGX+lZKaa3tESUzzY79JM0bthrJcUGSAOE8Wc6dZ8tX5ftgbDeD98uP1ppSfc/WZWYXr1aciNZj3ztStb6XcVJnrle4uxHkPOnzlMBIUUYtXRSgOaiztrEgFJzoJIyQIEVEJkqpTopGIRKt7RR6j9Y6MvdUiYjB9DC1h2dhvmhmtrKaGWRnXzngjEwant0naQc4L8UoDVDfY09S5uaJiN5ba9u2vZX6+fl5vV7/fHxs2/YfCewoSFzgY6UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=58x8 at 0x7F0963387670>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forehead_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "coIc6JwgOeNl"
   },
   "outputs": [],
   "source": [
    "forehead_data=np.array(forehead_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVX8V6wiDRSw",
    "outputId": "eed932ab-8b68-44ea-8421-430a882f279f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[206, 160, 126],\n",
       "        [209, 163, 129],\n",
       "        [211, 165, 131],\n",
       "        ...,\n",
       "        [233, 192, 160],\n",
       "        [233, 192, 160],\n",
       "        [232, 191, 159]],\n",
       "\n",
       "       [[207, 161, 127],\n",
       "        [210, 164, 130],\n",
       "        [211, 165, 131],\n",
       "        ...,\n",
       "        [233, 193, 158],\n",
       "        [233, 193, 158],\n",
       "        [234, 191, 157]],\n",
       "\n",
       "       [[208, 162, 128],\n",
       "        [211, 165, 131],\n",
       "        [212, 166, 132],\n",
       "        ...,\n",
       "        [233, 193, 158],\n",
       "        [235, 192, 158],\n",
       "        [234, 191, 157]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[207, 161, 127],\n",
       "        [211, 165, 131],\n",
       "        [211, 165, 131],\n",
       "        ...,\n",
       "        [228, 189, 158],\n",
       "        [228, 187, 157],\n",
       "        [233, 192, 162]],\n",
       "\n",
       "       [[205, 159, 125],\n",
       "        [209, 163, 129],\n",
       "        [210, 164, 130],\n",
       "        ...,\n",
       "        [219, 182, 153],\n",
       "        [219, 180, 151],\n",
       "        [224, 185, 156]],\n",
       "\n",
       "       [[202, 156, 122],\n",
       "        [207, 161, 127],\n",
       "        [209, 163, 129],\n",
       "        ...,\n",
       "        [193, 157, 131],\n",
       "        [175, 138, 112],\n",
       "        [164, 127, 101]]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forehead_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xeuxDBzDRZo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffxQ8ZsAaM43"
   },
   "outputs": [],
   "source": [
    "def colour_average1(image):\n",
    "  data=np.array(image)\n",
    "  shape=data.shape\n",
    "  rows=shape[0]\n",
    "  final_list=[]\n",
    "  c=0\n",
    "  for iterator in range(rows):\n",
    "    for x in data[iterator]:\n",
    "      list1=[x[0], x[1], x[2]]\n",
    "      final_list.append(list1)\n",
    "  df=pd.DataFrame(final_list, columns=['R', 'G', 'B'])\n",
    "  X=copy.copy(df)\n",
    "  X+=256\n",
    "  for i in range(len(X[\"R\"])):\n",
    "    if X[\"R\"][i]>256:\n",
    "      c=c+1\n",
    "      X[\"R\"][i]=df[\"R\"][i]\n",
    "  for i in range(len(X[\"G\"])):\n",
    "    if X[\"G\"][i]>256:\n",
    "      X[\"G\"][i]=df[\"G\"][i]\n",
    "  for i in range(len(X[\"B\"])):\n",
    "    if X[\"B\"][i]>256:\n",
    "      X[\"B\"][i]=df[\"B\"][i]\n",
    "  Red=X[\"R\"]\n",
    "  Green=X[\"G\"]\n",
    "  Blue=X[\"B\"]\n",
    "  rm=np.mean(Red)\n",
    "  gm=np.mean(Green)\n",
    "  bm=np.mean(Blue)\n",
    "  rs=np.std(Red)\n",
    "  gs=np.std(Green)\n",
    "  bs=np.std(Blue)\n",
    "  red_trim=stats.tmean(Red, (rm-rs, rm+rs))\n",
    "  green_trim=stats.tmean(Green, (gm-gs, gm+gs))\n",
    "  blue_trim=stats.tmean(Blue, (bm-bs, bm+bs))\n",
    "  area=len(Red)\n",
    "  return [red_trim, green_trim, blue_trim, area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62TeNNPjr-Xs"
   },
   "outputs": [],
   "source": [
    "def colour_average(image):\n",
    "  data=np.array(image)\n",
    "  shape=data.shape\n",
    "  rows=shape[0]\n",
    "  red=[]\n",
    "  green=[]\n",
    "  blue=[]\n",
    "  r=[]\n",
    "  g=[]\n",
    "  b=[]\n",
    "  c=0\n",
    "  for iterator in range(rows):\n",
    "    for x in data[iterator]:\n",
    "      red.append(x[0])\n",
    "      green.append(x[1])\n",
    "      blue.append(x[2])\n",
    "  rm=np.mean(red)\n",
    "  gm=np.mean(green)\n",
    "  bm=np.mean(blue)\n",
    "  rs=np.std(red)\n",
    "  gs=np.std(green)\n",
    "  bs=np.std(blue)\n",
    "  for item in red:\n",
    "    if item>=rm and item<=rm+rs:\n",
    "      r.append(item)\n",
    "  r=[int(x)*int(x) for x in r]\n",
    "  #root mean square\n",
    "  for item in green:\n",
    "    if item>=gm and item<=gm+gs:\n",
    "      g.append(item)\n",
    "  g=[int(x)*int(x) for x in g]\n",
    "  for item in blue:\n",
    "    if item>=bm and item<=bm+bs:\n",
    "      b.append(item)\n",
    "  b=[int(x)*int(x) for x in b]\n",
    "  red_trim=math.sqrt(sum(r)/len(r))\n",
    "  green_trim=math.sqrt(sum(g)/len(g))\n",
    "  blue_trim=math.sqrt(sum(b)/len(b))\n",
    "  area=min(len(r), len(g), len(b))\n",
    "  return [red_trim, green_trim, blue_trim, area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zp_g-_kSeMq5"
   },
   "outputs": [],
   "source": [
    "f=colour_average (forehead_crop)\n",
    "g=colour_average (nose_crop)\n",
    "#h=colour_average (cheek_crop)\n",
    "m=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vLkyh0M-rnz",
    "outputId": "29ea9e65-5864-471a-c355-99a25fd31d05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[237.4628215950265, 205.6523963565912, 175.93102793924754, 267]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EH4k6EtKk0I3"
   },
   "outputs": [],
   "source": [
    "def weighted_average (list1, list2, list3):\n",
    "  list_ans=[]\n",
    "  area1=list1[3]\n",
    "  area2=list2[3]\n",
    "  #area3=list3[3]\n",
    "  for i in range(3):\n",
    "    #ans=(list1[i]*area1 + list2[i]*area2 + list3[i]*area3)/(area1+area2+area3)\n",
    "    ans=(list1[i]*area1 + list2[i]*area2)/(area1+area2)\n",
    "    list_ans.append(ans)\n",
    "  return list_ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fohVmVOx1jQj",
    "outputId": "dbde7878-336d-42c7-c364-15f5e9eb977f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[237.57878765907392, 203.68228987147305, 174.14486521324295]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_average(f,g,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-skk0EZGxPwq"
   },
   "outputs": [],
   "source": [
    "#fdata=np.array(forehead_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I58KCVp8JDQK",
    "outputId": "dffd1e31-f959-44bc-a886-2d1fb66894e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 238, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMH7rlHjJhJB"
   },
   "outputs": [],
   "source": [
    "\"\"\"def colour_averagehsv(image):\n",
    "  data=np.array(image)\n",
    "  shape=data.shape\n",
    "  rows=shape[0]\n",
    "  hue=[]\n",
    "  saturation=[]\n",
    "  value=[]\n",
    "  hsv=[]\n",
    "  r=[]\n",
    "  g=[]\n",
    "  b=[]\n",
    "  c=0\n",
    "  for iterator in range(rows):\n",
    "    for x in data[iterator]:\n",
    "      (red,green,blue)=(x[0]/255, x[1]/255, x[2]/255)\n",
    "      (h,s,v)=colorsys.rgb_to_hsv(red,green,blue)\n",
    "      (h, s, v) = (int(h * 179), int(s * 255), int(v * 255))\n",
    "      hue.append(h)\n",
    "      saturation.append(s)\n",
    "      value.append(v)\n",
    "  rm=np.mean(hue)\n",
    "  gm=np.mean(saturation)\n",
    "  bm=np.mean(value)\n",
    "  rs=np.std(hue)\n",
    "  gs=np.std(saturation)\n",
    "  bs=np.std(value)\n",
    "  for item in hue:\n",
    "    if item>=rm and item<=rm+rs:\n",
    "      r.append(item)\n",
    "      c=c+1\n",
    "  r=[float(x)*float(x) for x in r]\n",
    "  for item in saturation:\n",
    "    if item>=gm and item<=gm+gs:\n",
    "      g.append(item)\n",
    "  g=[float(x)*float(x) for x in g]\n",
    "  for item in value:\n",
    "    if item>=bm and item<=bm+bs:\n",
    "      b.append(item)\n",
    "  b=[float(x)*float(x) for x in b]\n",
    "  red_trim=math.sqrt(sum(r)/len(r))\n",
    "  green_trim=math.sqrt(sum(g)/len(g))\n",
    "  blue_trim=math.sqrt(sum(b)/len(b))\n",
    "  area=min(len(r), len(g), len(b))\n",
    "  return [int(red_trim), int(green_trim), int(blue_trim), area]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ef5dFT07VzVX",
    "outputId": "59aa7abc-367d-4330-f961-71f1883c96e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 85, 185, 11]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#colour_averagehsv(forehead_crop)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
